{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Street</th>\n",
       "      <th>City</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EASY WAY CONSTRUCTIONS PTY LTD</td>\n",
       "      <td>23 SANDPIPER DR</td>\n",
       "      <td>MIDWAY POINT</td>\n",
       "      <td>7171</td>\n",
       "      <td>TAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DAWSON CONSTRUCTION QLD PTY LTD</td>\n",
       "      <td>7 NELSON CRT</td>\n",
       "      <td>BENOWA</td>\n",
       "      <td>4217</td>\n",
       "      <td>QLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VICTORIA POLICE</td>\n",
       "      <td>LEVEL 11/313 SPENCER ST</td>\n",
       "      <td>DOCKLANDS</td>\n",
       "      <td>3008</td>\n",
       "      <td>VIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MICK ROSE PLUMBING</td>\n",
       "      <td>UNIT 2-25 BAYVISTA RISE</td>\n",
       "      <td>SOMERVILLE</td>\n",
       "      <td>3912</td>\n",
       "      <td>VIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RAYMOND C POBJOY &amp; ASSOCIATES</td>\n",
       "      <td>4/868 MALVERN RD</td>\n",
       "      <td>ARMADALE</td>\n",
       "      <td>3143</td>\n",
       "      <td>VIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PKC ELECTRICAL</td>\n",
       "      <td>33 MADELINE ST</td>\n",
       "      <td>MUDGEERABA</td>\n",
       "      <td>4213</td>\n",
       "      <td>QLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SEATONS ALUMINIUM</td>\n",
       "      <td>91 MAITLAND RD</td>\n",
       "      <td>SANDGATE</td>\n",
       "      <td>2304</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JACARANDA MOTOR LODGE</td>\n",
       "      <td>PO BOX 230</td>\n",
       "      <td>GRAFTON</td>\n",
       "      <td>2460</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DTS BUILDERS</td>\n",
       "      <td>PO BOX 1649 MILTON</td>\n",
       "      <td>MILTON</td>\n",
       "      <td>4064</td>\n",
       "      <td>QLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DARYL ANSELL</td>\n",
       "      <td>7 COOLUM CL</td>\n",
       "      <td>KEWARRA BEACH</td>\n",
       "      <td>4879</td>\n",
       "      <td>QLD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name                                Street  \\\n",
       "0  EASY WAY CONSTRUCTIONS PTY LTD        23 SANDPIPER DR                        \n",
       "1  DAWSON CONSTRUCTION QLD PTY LTD       7 NELSON CRT                           \n",
       "2  VICTORIA POLICE                       LEVEL 11/313 SPENCER ST                \n",
       "3  MICK ROSE PLUMBING                    UNIT 2-25 BAYVISTA RISE                \n",
       "4  RAYMOND C POBJOY & ASSOCIATES         4/868 MALVERN RD                       \n",
       "5  PKC ELECTRICAL                        33 MADELINE ST                         \n",
       "6  SEATONS ALUMINIUM                     91 MAITLAND RD                         \n",
       "7  JACARANDA MOTOR LODGE                 PO BOX 230                             \n",
       "8  DTS BUILDERS                          PO BOX 1649 MILTON                     \n",
       "9  DARYL ANSELL                          7 COOLUM CL                            \n",
       "\n",
       "                                   City Postcode  State  \n",
       "0  MIDWAY POINT                             7171  TAS    \n",
       "1  BENOWA                                   4217  QLD    \n",
       "2  DOCKLANDS                                3008  VIC    \n",
       "3  SOMERVILLE                               3912  VIC    \n",
       "4  ARMADALE                                 3143  VIC    \n",
       "5  MUDGEERABA                               4213  QLD    \n",
       "6  SANDGATE                                 2304  NSW    \n",
       "7  GRAFTON                                  2460  NSW    \n",
       "8  MILTON                                   4064  QLD    \n",
       "9  KEWARRA BEACH                            4879  QLD    "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "\n",
    "df = pd.read_csv(\"addresses.csv\", encoding = \"ISO-8859-1\")\n",
    "df = df.sample(frac=1).reset_index(drop=True) #Shuffle data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.State.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list = [text.strip() for text in df.City.unique().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities = pd.DataFrame(city_list)\n",
    "len(df_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_list = [text.strip() for text in df.Street.unique().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_streets = pd.DataFrame(street_list,columns=[\"street\"])\n",
    "df_streets.iloc[5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_list = [str(text).strip() for text in df.Name.unique().tolist()]\n",
    "df_buildings = pd.DataFrame(building_list,columns=[\"bulding\"])\n",
    "df_buildings.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to encode/decode vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Allowable characters for the encoded representation\n",
    "chars = list(string.digits + string.ascii_lowercase + string.punctuation + string.whitespace)\n",
    "\n",
    "def chars_encode(characters: str) ->np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a string into a list of vocab indices\n",
    "    :param characters: the string to convert\n",
    "    :return: the an array of vocab indices\n",
    "    \"\"\"\n",
    "    result = list()\n",
    "    for c in characters.lower():\n",
    "        try:\n",
    "            result.append(chars.index(c))\n",
    "        except ValueError:\n",
    "            result.append(0)\n",
    "    return np.array(result, dtype=np.int64)\n",
    "\n",
    "def chars_decode(vocab_indices : np.ndarray)->str:\n",
    "    result = []\n",
    "    for n in vocab_indices:\n",
    "        result.append(chars[n])\n",
    "    \n",
    "    return \"\".join(result)\n",
    "\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = [\n",
    "    \"building\",\n",
    "    'street',  \n",
    "    'city',  \n",
    "    'postcode',  \n",
    "    'state',  \n",
    "    'blank'\n",
    "]\n",
    "n_labels = len(labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Label generation function \n",
    "# Add a bit of randonmess (Typos, commas, random sentences in front and behind address, etc..)\n",
    "# y = { street, postcode, city, state, unknown  }. eg y = {1,0,0,0,0} ->  street\n",
    "import random\n",
    "\n",
    "def generate_label(text: str, field_name: str) -> (str,np.ndarray):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    labels_vector = np.zeros((len(text), n_labels), dtype=np.float32)\n",
    "    labels_vector[:, labels_list.index(field_name)] = 1\n",
    "    return (text,labels_vector)\n",
    "\n",
    "def generate_address(building:str, \n",
    "                     street:str, \n",
    "                     city:str, \n",
    "                     postcode:str, \n",
    "                     state: str) -> (str, np.ndarray):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    building_label = generate_label(building,\"building\")\n",
    "    street_label = generate_label(street,\"street\")\n",
    "    city_label = generate_label(city,\"city\")\n",
    "    postcode_label= generate_label(postcode, \"postcode\")\n",
    "    state_label = generate_label(state, \"state\")\n",
    "    concat_text = []\n",
    "    concat_label = []\n",
    "    # Chance of inserting seperator between text\n",
    "    sep = random.choice([\"\\n\",\",\",\" \"])\n",
    "    sep_label = generate_label(sep,'blank')\n",
    "    suburb_state_code = [city_label, postcode_label, state_label]\n",
    "    random.shuffle(suburb_state_code)\n",
    "    address_vector = [street_label] + suburb_state_code\n",
    "    if building_label:\n",
    "         address_vector = [building_label] + address_vector\n",
    "    for i in range(0,len(address_vector)) :\n",
    "        each = address_vector[i]\n",
    "        concat_text.append(each[0])\n",
    "        concat_label.append(each[1])\n",
    "        if (i < len(address_vector)-1):\n",
    "            concat_text.append(sep_label[0])\n",
    "            concat_label.append(sep_label[1])  \n",
    "    merged_text = \"\".join(concat_text)\n",
    "\n",
    "    merged_labels = np.concatenate(concat_label, axis=0)\n",
    "    return merged_text,merged_labels\n",
    "\n",
    "def to_category(labels: np.ndarray):\n",
    "    label_names = []\n",
    "    for i in range(len(labels)):\n",
    "        each = labels[i]\n",
    "        idx = each.tolist().index(True)\n",
    "        label_names.append(idx)\n",
    "    return label_names\n",
    "                     \n",
    "address = generate_address(\"test\",\"16 colville cresc\", \"keysborough\", \"3173\", \"vic\")\n",
    "address[1]\n",
    "#print(to_category(address[1]))\n",
    "#print(chars_encode(address[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data (Dev, Test, Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x test: 3000\n",
      "Size of y test: 3000\n",
      "Size of x train: 30000\n",
      "Size of y train: 30000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Shuffle data into dev, test, train (1K,1K,30K)\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "x_train = []\n",
    "y_train = []\n",
    "for index, row in df.iterrows():\n",
    "    building = str(row.Name).strip()\n",
    "    street = row.Street.strip()\n",
    "    city = row.City.strip()\n",
    "    postcode = row.Postcode.strip()\n",
    "    state = row.State.strip()\n",
    "    if random.random() < 0.5:\n",
    "        building = \"\"\n",
    "    if index < 3000:\n",
    "        address = generate_address(building, street, city, postcode, state)\n",
    "        address_encoded = chars_encode(address[0])\n",
    "        labels = address[1]\n",
    "        x_test.append(address_encoded)\n",
    "        y_test.append(labels)\n",
    "    elif index < 33000:\n",
    "        address = generate_address(building, street, city, postcode, state)\n",
    "        address_encoded = chars_encode(address[0])\n",
    "        labels = address[1]\n",
    "        x_train.append(address_encoded)\n",
    "        y_train.append(labels)\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "\n",
    "print(\"Size of x test:\", len(x_test))\n",
    "print(\"Size of y test:\", len(y_test))\n",
    "print(\"Size of x train:\", len(x_train))\n",
    "print(\"Size of y train:\", len(y_train))\n",
    "\n",
    "x_train = pad_sequences(x_train, padding='post')\n",
    "y_train = pad_sequences(y_train, padding='post')\n",
    "x_test = pad_sequences(x_test, padding='post')\n",
    "y_test = pad_sequences(y_test, padding='post')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 30000 samples, validate on 3000 samples\n",
      "Epoch 1/4\n",
      "30000/30000 [==============================] - 110s 4ms/step - loss: 0.0796 - accuracy: 0.9402 - val_loss: 0.0104 - val_accuracy: 0.9940\n",
      "Epoch 2/4\n",
      "30000/30000 [==============================] - 104s 3ms/step - loss: 0.0059 - accuracy: 0.9960 - val_loss: 0.0080 - val_accuracy: 0.9957\n",
      "Epoch 3/4\n",
      "30000/30000 [==============================] - 112s 4ms/step - loss: 0.0034 - accuracy: 0.9977 - val_loss: 0.0049 - val_accuracy: 0.9968\n",
      "Epoch 4/4\n",
      "30000/30000 [==============================] - 110s 4ms/step - loss: 0.0026 - accuracy: 0.9982 - val_loss: 0.0037 - val_accuracy: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x64b1d3b50>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model, Model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Max number of characters in sentence\n",
    "batch_size = 32\n",
    "data_dim = 74\n",
    "nb_classes = 6\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(74, 64, input_length=None, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True,)))\n",
    "model.add(TimeDistributed(Dense(6, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=4,\n",
    "          validation_data=[x_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plumbing kenny 16 colville cresc keysborough VIC 3173\n",
      "P -> building\n",
      "l -> building\n",
      "u -> building\n",
      "m -> building\n",
      "b -> building\n",
      "i -> building\n",
      "n -> building\n",
      "g -> building\n",
      "  -> building\n",
      "k -> building\n",
      "e -> building\n",
      "n -> building\n",
      "n -> building\n",
      "y -> building\n",
      "  -> blank\n",
      "1 -> street\n",
      "6 -> street\n",
      "  -> street\n",
      "c -> street\n",
      "o -> street\n",
      "l -> street\n",
      "v -> street\n",
      "i -> street\n",
      "l -> street\n",
      "l -> street\n",
      "e -> street\n",
      "  -> street\n",
      "c -> street\n",
      "r -> street\n",
      "e -> street\n",
      "s -> street\n",
      "c -> street\n",
      "  -> blank\n",
      "k -> city\n",
      "e -> city\n",
      "y -> city\n",
      "s -> city\n",
      "b -> city\n",
      "o -> city\n",
      "r -> city\n",
      "o -> city\n",
      "u -> city\n",
      "g -> city\n",
      "h -> city\n",
      "  -> blank\n",
      "V -> state\n",
      "I -> state\n",
      "C -> state\n",
      "  -> blank\n",
      "3 -> postcode\n",
      "1 -> postcode\n",
      "7 -> postcode\n",
      "3 -> postcode\n"
     ]
    }
   ],
   "source": [
    "address = generate_address(\"Plumbing kenny\",\"16 colville cresc\", \"keysborough\", \"3173\", \"VIC\")\n",
    "x_text = address[0]\n",
    "print(x_text)\n",
    "x_encoded = chars_encode(x_text)\n",
    "x_encoded = x_encoded.reshape(1,len(x_encoded))\n",
    "predict = model.predict_classes(x_encoded,verbose=0)\n",
    "predict\n",
    "i = 0\n",
    "for p in predict:\n",
    "    for x in p:\n",
    "        print(x_text[i],'->',labels_list[x])\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1]\n",
      "  [ 2]\n",
      "  [ 3]\n",
      "  [ 4]\n",
      "  [ 5]\n",
      "  [ 6]\n",
      "  [ 7]\n",
      "  [ 8]\n",
      "  [ 9]\n",
      "  [10]]\n",
      "\n",
      " [[ 2]\n",
      "  [ 3]\n",
      "  [ 4]\n",
      "  [ 5]\n",
      "  [ 6]\n",
      "  [ 7]\n",
      "  [ 8]\n",
      "  [ 9]\n",
      "  [10]\n",
      "  [11]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
