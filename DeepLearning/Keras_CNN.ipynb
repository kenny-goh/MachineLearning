{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0627 20:39:36.834237  6104 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize the Convolution network\n",
    "cnn_clf = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding convolution and pooling layers\n",
    "\n",
    "# Param 1: Use 32 feature dectors for the dogs and cat images\n",
    "# Param 2: 3x3 feature detector\n",
    "# Param 3: 64x64 for images, 3 for RGB channels\n",
    "# Param 4: Rectifier Activation function\n",
    "conv1 = Conv2D(32, (3,3), input_shape=(64,64,3), activation='relu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 20:43:08.144923  6104 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0627 20:43:08.158375  6104 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add this convolution layer to the neural network\n",
    "cnn_clf.add(conv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 20:44:23.475907  6104 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a pooling layer by using a 2x2 MAX pooling filter \n",
    "pool1 = MaxPooling2D(pool_size=(2,2))\n",
    "cnn_clf.add(pool1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second convolution layer\n",
    "# Note the second convolution layer can automatically\n",
    "# detect input shape from the previous layer\n",
    "conv2 = Conv2D(32,(3,3),activation='relu')\n",
    "cnn_clf.add(conv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the input\n",
    "cnn_clf.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Dense layers\n",
    "\n",
    "# First layer\n",
    "# Use 128 nodes\n",
    "h1 = Dense(units=128, activation='relu')\n",
    "cnn_clf.add(h1)\n",
    "\n",
    "# Second layer\n",
    "# Use sigmoid activation function since we want\n",
    "# a binary outcome.\n",
    "h2 = Dense(units=1, activation=\"sigmoid\")\n",
    "cnn_clf.add(h2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 20:58:31.653337  6104 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0627 20:58:31.671257  6104 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0627 20:58:31.677239  6104 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Compile the CNN\n",
    "cnn_clf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images to improve training\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_setgen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "\n",
    "#Scale the test sets\n",
    "test_setgen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating training and test sets\n",
    "training_data = train_setgen.flow_from_directory(r'./Datasets/animal_data/training_set',\n",
    "                                                 target_size = (64,64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode='binary')\n",
    "\n",
    "test_data = test_setgen.flow_from_directory(r'./Datasets/animal_data/test_set',\n",
    "                                                 target_size = (64,64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 20:58:36.429433  6104 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 74s 294ms/step - loss: 0.6835 - acc: 0.5616 - val_loss: 0.6682 - val_acc: 0.5750\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 47s 187ms/step - loss: 0.6293 - acc: 0.6420 - val_loss: 0.6291 - val_acc: 0.6470\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 47s 189ms/step - loss: 0.6016 - acc: 0.6755 - val_loss: 0.5874 - val_acc: 0.7000\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 53s 211ms/step - loss: 0.5824 - acc: 0.6919 - val_loss: 0.5876 - val_acc: 0.6965\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.5513 - acc: 0.7198 - val_loss: 0.5436 - val_acc: 0.7285\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 50s 200ms/step - loss: 0.5236 - acc: 0.7395 - val_loss: 0.5380 - val_acc: 0.7350\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 47s 188ms/step - loss: 0.5025 - acc: 0.7502 - val_loss: 0.4968 - val_acc: 0.7655\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 50s 200ms/step - loss: 0.4733 - acc: 0.7754 - val_loss: 0.5024 - val_acc: 0.7700\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.4558 - acc: 0.7868 - val_loss: 0.4963 - val_acc: 0.7605\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 49s 195ms/step - loss: 0.4446 - acc: 0.7944 - val_loss: 0.5029 - val_acc: 0.7585\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.4198 - acc: 0.8061 - val_loss: 0.4661 - val_acc: 0.7825\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.4082 - acc: 0.8077 - val_loss: 0.4645 - val_acc: 0.7905\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 48s 191ms/step - loss: 0.3977 - acc: 0.8200 - val_loss: 0.4836 - val_acc: 0.7730\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.3891 - acc: 0.8231 - val_loss: 0.4915 - val_acc: 0.7750\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.3613 - acc: 0.8400 - val_loss: 0.4786 - val_acc: 0.7790\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.3411 - acc: 0.8510 - val_loss: 0.4669 - val_acc: 0.8140\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 47s 189ms/step - loss: 0.3335 - acc: 0.8516 - val_loss: 0.4943 - val_acc: 0.7995\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 50s 198ms/step - loss: 0.3149 - acc: 0.8696 - val_loss: 0.4753 - val_acc: 0.8005\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 50s 199ms/step - loss: 0.2968 - acc: 0.8769 - val_loss: 0.4842 - val_acc: 0.8050\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 52s 209ms/step - loss: 0.2965 - acc: 0.8685 - val_loss: 0.4918 - val_acc: 0.7975\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 49s 195ms/step - loss: 0.2809 - acc: 0.8777 - val_loss: 0.5227 - val_acc: 0.7975\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 51s 204ms/step - loss: 0.2660 - acc: 0.8855 - val_loss: 0.5120 - val_acc: 0.8080\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 49s 197ms/step - loss: 0.2613 - acc: 0.8906 - val_loss: 0.5044 - val_acc: 0.8105\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 50s 200ms/step - loss: 0.2370 - acc: 0.9011 - val_loss: 0.5526 - val_acc: 0.7900\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 51s 205ms/step - loss: 0.2350 - acc: 0.9027 - val_loss: 0.5613 - val_acc: 0.8110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ffa8317b8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine accuracy\n",
    "cnn_clf.fit_generator(training_data, steps_per_epoch=(8000/32),\n",
    "                      epochs=25,\n",
    "                      validation_data=test_data,\n",
    "                      validation_steps=(2000/32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model \n",
    "from keras.models import load_model\n",
    "\n",
    "model = cnn_clf\n",
    "model.save('dog_cat_cnn_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('dog_cat_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Cat\n"
     ]
    }
   ],
   "source": [
    "# Predict a cat after training\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_path = r'.\\Datasets\\animal_data\\test_set\\cats\\cat.4023.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64,3))\n",
    "img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "# check prediction\n",
    "pred = model.predict(img_tensor)\n",
    "#classes = test_data.class_indices    \n",
    "if round(pred[0][0],0) == 0:\n",
    "    print(\"Prediction: Cat\")\n",
    "else:\n",
    "    print(\"Prediction: Dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Dog\n"
     ]
    }
   ],
   "source": [
    "# Predict a cat after training\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_path = r'.\\Datasets\\animal_data\\test_set\\dogs\\dog.4089.jpg'\n",
    "img = image.load_img(img_path, target_size=(64, 64,3))\n",
    "img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "# check prediction\n",
    "pred = model.predict(img_tensor)\n",
    "#classes = test_data.class_indices    \n",
    "if round(pred[0][0],0) == 0:\n",
    "    print(\"Prediction: Cat\")\n",
    "else:\n",
    "    print(\"Prediction: Dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
